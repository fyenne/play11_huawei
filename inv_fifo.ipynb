{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- select * from  dsc_dwd.dwd_wh_dsc_inventory_dtl_di \n",
    "# -- where src = 'scale'\n",
    "# -- and data_source in ('scale_hpi', 'scale_michelin', 'scale_fas', 'scale_bose')\n",
    "# -- and inc_day in ('20211124', '20211117', '20211110', '20211103', \n",
    "# -- '20211027', '20211020', '20211013','20211006')\n",
    "# -- and usage_flag = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date, timedelta\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(os.listdir('data_down'))\n",
    "\n",
    "\n",
    "def allsundays(year):\n",
    "    return pd.Series(pd.date_range(start=str(year), end=str(year+12), \n",
    "                        freq='2W-WED').strftime('%Y%m%d'))\n",
    "fridays = tuple([i for i in list(allsundays(2021)[allsundays(2021) < date.today().strftime('%Y%m%d')][-8:])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./data_down/inv_wmos.csv', sep='\\001')\n",
    "df.columns = [re.sub('\\w+\\.', '', i) for i in list(df.columns)]\n",
    "df = df.dropna(how = 'all', axis =1)\n",
    "time_cols = pd.Series(df.columns)[\n",
    "    pd.Series(df.columns).str.lower().str.findall('date|time').apply(len)>0\n",
    "    ]\n",
    "df[time_cols] = df[time_cols].apply(lambda x: x.str.slice(0,10))\n",
    "df['lock_codes'] = df['lock_codes']. fillna('Available')\n",
    "\n",
    "df9 = df\n",
    "\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# sql = \"\"\"\n",
    "#     select * from  dsc_dwd.dwd_wh_dsc_inventory_dtl_di \n",
    "#     where src = 'scale'\n",
    "#     and ou_code in (\n",
    "#     'HPPXXWHWDS', \n",
    "#     'MICHETCTGS'\n",
    "#     'COSTASHHTS',\n",
    "#     'ZEBRASHALS'\n",
    "#     )\n",
    "#     and inc_day in \"\"\"+ str(fridays) + \"\"\"\n",
    "#     and usage_flag = '1'\n",
    "#     \"\"\"\n",
    "# print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code = ''\n",
    "# df0 = pd.DataFrame()\n",
    "# scan_len = len(df['inc_day'].unique())  # 8\n",
    "# somelen = 8 - scan_len\n",
    "# print([scan_len,somelen])\n",
    "\n",
    "# def load_data(ou_code):\n",
    "#     \"\"\"\n",
    "#     load bose data;\n",
    "#     所有类型的qty都要加起来哦\n",
    "#     只选择有多个收货日期的货物\n",
    "#     \"\"\"\n",
    "#     global code, df, bose_inv, df0\n",
    "#     df0 = pd.DataFrame()\n",
    "#     df = df9\n",
    "#     df = df[df['ou_code'].astype(str) == ou_code]\n",
    "\n",
    "#     def fifo_fefo(df, type):\n",
    "#         if type == 'fifo':\n",
    "#             df['recived_date'] = pd.to_datetime(df['recived_date'])\n",
    "#             df['fifo_fefo'] = 'fifo'\n",
    "#         elif type == 'fefo':\n",
    "#             df['recived_date'] = pd.to_datetime(df['expiration_date'].str.slice(0,10))\n",
    "#             df['fifo_fefo'] = 'fefo'\n",
    "#         else: \n",
    "#             pass\n",
    "#         return df \n",
    "\n",
    "#     if ou_code in {'HPPXXWHWDS', 'HPPXXSHMGS'}:\n",
    "#         # hp wh\n",
    "#         print(\"load_data\", \" 'HPPXXWHWDS', 'HPPXXSHMGS' \")\n",
    "#         code = '(QH|27|QI)'\n",
    "#         df = fifo_fefo(df, 'fifo')\n",
    "\n",
    "#     elif ou_code in {'MICHETCTGS', 'MICHESHXCS'}:\n",
    "#         print(\"load_data\", \" 'MICHETCTGS', 'MICHESHXCS' \")\n",
    "#         df = df[df['expiration_date'] != '4712-12-31']\n",
    "#         # mich tc, rt,m  FEFO\n",
    "#         code = '(BLOCKED_TH|RETURN)'\n",
    "#         print(\"mich_if_if\")\n",
    "#         df = fifo_fefo(df, 'fefo')\n",
    "\n",
    "#     elif ou_code == 'COSTASHHTS':\n",
    "#         # COSTASHHTS expiration_date 没有空值.\n",
    "#         df1 = df[df['expiration_date'] == '4712-12-31'] # fifo @# scale datetime. need redefine when other wms sys/..\n",
    "#         df2 = df[df['expiration_date'] != '4712-12-31'] # fefo\n",
    "#         df1 = fifo_fefo(df1, 'fifo')\n",
    "#         df2 = fifo_fefo(df2, 'fefo')\n",
    "#         df = pd.concat([df1, df2], axis = 0)\n",
    "#         code = '(blocked)'\n",
    "\n",
    "#     elif ou_code == 'SIEMESUEPS':\n",
    "#         pass\n",
    "\n",
    "#     # print(code)\n",
    "    \n",
    "    \n",
    "#     df = df[['wms_company_name', 'wms_warehouse_id','sku_code', 'sku_name', 'sku_desc', 'location',\\\n",
    "#         'lock_codes', 'on_hand_qty', 'in_transit_qty','allocated_qty', 'shelf_days', \n",
    "#         'recived_date','usage_flag', 'fifo_fefo','inc_day', 'ou_code']]\n",
    "#     df['qty'] = df['on_hand_qty']\n",
    "    \n",
    "    \n",
    "#     # 没有重复的 目前看....aaa\n",
    "#     print(\"===============================oucode :: %s=================================\"%df['ou_code'].unique())\n",
    "#     print(df['on_hand_qty'].describe())\n",
    "\n",
    "#     df = df.sort_values(['sku_code', 'recived_date']).groupby(\n",
    "#         ['recived_date', 'sku_code', 'lock_codes','inc_day', 'wms_warehouse_id', 'fifo_fefo'],\n",
    "#         # dropna = False\n",
    "#         ).agg(\n",
    "#     {\n",
    "#         'qty':'sum',\n",
    "#         'location': set\n",
    "#         # ? 这里如果group by location德华会有问题, 列数,miasjdijaisjd\n",
    "#     }\n",
    "#     ).sort_values(['sku_code', 'recived_date']).reset_index()\n",
    "#     # 只选择有多个收货日期的货物\n",
    "#     filter0 = df.groupby(['sku_code'])['recived_date'].agg(\n",
    "#     {\n",
    "#         set\n",
    "#     }\n",
    "#         ).reset_index()\n",
    "\n",
    "#     filter0 = pd.DataFrame(filter0[filter0['set'].apply(len)> 1]['sku_code'].drop_duplicates())\n",
    "#     bose_inv = filter0.merge(df, on = ['sku_code'], how = 'inner')\\\n",
    "#         .sort_values(['recived_date','sku_code', 'inc_day'])\n",
    "#     bose_inv['ou_code'] = ou_code\n",
    "#     print(bose_inv.head())\n",
    "#     return bose_inv, code\n",
    "\n",
    "# def snapshot():\n",
    "#     \"\"\"\n",
    "#     pivot table. inc_day 快照 作为 cols\n",
    "#     添加标记.\n",
    "#     \"\"\"\n",
    "#     global df0, bose_inv\n",
    "#     df0 = pd.DataFrame()\n",
    "#     for i in bose_inv['sku_code'].unique():\n",
    "#         df_out = bose_inv[bose_inv['sku_code'] == i]\\\n",
    "#             .pivot_table(columns='inc_day', index = 'recived_date', values='qty').reset_index()\n",
    "#         df_out['sku_code'] = i\n",
    "#         df0 = pd.concat([df0, df_out], axis = 0)\n",
    "#     try:\n",
    "#         df0.columns = df0.columns.get_level_values(level=1)\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "#     if re.search('(\\d+)', str(df0.columns[0])) == None:\n",
    "#         df0.columns = ['received_date', df0.columns[1],  df0.columns[2], 'sku']\n",
    "#         df0 = df0[[df0.columns[1], df0.columns[2], 'received_date', 'sku']]\n",
    "#         print('hah, mutated')\n",
    "#     else:\n",
    "#         print('ha. no need mutations')\n",
    "#         pass\n",
    "\n",
    "#     # if test.columns[0]  == '':\n",
    "#     #     test.columns = ['received_date', test.columns[1],  test.columns[2], 'sku']\n",
    "#     #     test = test[[test.columns[1], test.columns[2], 'received_date', 'sku']]\n",
    "#     # else:\n",
    "#     #     pass\n",
    "#     print(\"snap_df0_column before in snap\", df0.columns, \"len of df0 in snap\", (df0.shape))\n",
    "#     df0 = df0.reset_index(drop = True) # 4 \n",
    "#     print(df0.head())\n",
    "\n",
    "#     # df0 = pd.DataFrame(np.zeros([3, 4]))\n",
    "#     \"\"\"\n",
    "#     添加缺失列\n",
    "#     \"\"\"\n",
    "#     if len(df0.columns) == 10:\n",
    "#         print(list(df0.columns[0:scan_len]))\n",
    "#         df0.columns = list(df0.columns[0:scan_len]) + ['received_date','sku']\n",
    "#         print(\"normal process in snap::%s\"%str(df0.shape))\n",
    "#     else:\n",
    "#         # pass\n",
    "#         print(\"auto fill enabled , ncol is: %s\" %(10 - len(df0.columns)))\n",
    "#         # somelen = 10 - len(df0.columns)\n",
    "#         # df_zero = pd.DataFrame(np.zeros([df0.shape[0], somelen]))\n",
    "#         # df0 = pd.concat([df_zero, df0], axis = 1)\n",
    "#         # df0.columns = list(\n",
    "#         #     np.repeat(0, (somelen))\n",
    "#         #     ) + list(\n",
    "#         #         df0.columns[0:(scan_len)]\n",
    "#         #         ) + ['received_date','sku']\n",
    "#         names = df0.columns[0:2]\n",
    "#         df_zero = pd.DataFrame(df0.iloc[:,0])\n",
    "#         df_zero2 = pd.DataFrame()\n",
    "#         # df_zero. copy()\n",
    "#         for i in range(0,somelen):\n",
    "#             df_zero2 = pd.concat([df_zero2, df_zero], axis = 1)\n",
    "\n",
    "#         print(df_zero2.head())\n",
    "\n",
    "#         df0 = pd.concat([df_zero2, df0], axis = 1)\n",
    "#         print(df0.head())\n",
    "#         df0.columns = list(range(11,11 + somelen)) + list(names) + ['received_date','sku']\n",
    "#     scan_len = 8\n",
    "#     print(df0.head())\n",
    "#     df0 = df0.sort_values(['sku', 'received_date'])\n",
    "#     df0['mark'] = 0\n",
    "#     df0['mark'] = df0['mark'].where(\n",
    "#         df0.iloc[:,  (scan_len - 1)].isna() == False, 'new')\n",
    "#         # df0.iloc[:, 0: (scan_len - 1)].isna().all(axis = 1) == False, 'new')\n",
    "#         # \n",
    "#     df0['mark'] = df0['mark'].where(\n",
    "#         ~df0.iloc[:,(scan_len - 1)].isna() , 'clear')\n",
    "#     # fill na~\n",
    "#     df0 = df0.fillna(0)\n",
    "#     bose_inv = bose_inv.rename({'sku_code':'sku', 'recived_date':'received_date'}, axis = 1)\\\n",
    "#         .reset_index(drop = True).drop(['inc_day', 'qty'], axis = 1)\n",
    "#     bose_inv = bose_inv.drop_duplicates(subset = ['sku', 'received_date', 'lock_codes'])\n",
    "#     df0 = df0.merge(bose_inv, on = ['sku','received_date'], how = 'left')\n",
    "\n",
    "#     # may lock\n",
    "#     df0['mark'] = df0['mark'].where(df0.iloc[:, 0:scan_len].fillna(0).nunique(axis = 1) > 1, 'may_lock')\n",
    "#     print(\"===========================snap!done for : %s=============================\" %df0['ou_code'].unique())\n",
    "#     return df0\n",
    "# # print(\"===============================mid_function_check=================================\")\n",
    "# def err_part():\n",
    "#     \"\"\"\n",
    "#     findout who are the naught peach.\n",
    "#     err 中干掉了 new 干掉了maylock \n",
    "#     \"\"\"\n",
    "#     global df0\n",
    "\n",
    "#     print(\"============================err_part!start: %s============================\"%str(df0.shape))\n",
    "#     scan_len = 8\n",
    "#     df_err = df0[df0['mark'] != 'new']\n",
    "#     # 补充可能被锁的标记\n",
    "#     # df_err['mark'] = df_err['mark'].where(df_err.iloc[:, 0:8].fillna(0).nunique(axis = 1) > 1, 'may_lock')\n",
    "#     # 干掉了maylock\n",
    "#     df_err = df_err[df_err['mark'] != 'may_lock'].sort_values(['sku', 'received_date'])\n",
    "#     # print(\"===============================scan_len_err_function--%s=================================\"%scan_len)\n",
    "#     # print(df_err.iloc[:,0:scan_len])\n",
    "#     df_err['change'] = df_err.iloc[:,0:scan_len].diff(axis = 1).sum(axis = 1)\n",
    "#     shift = df_err.groupby(['sku', 'wms_warehouse_id']).shift(1) \n",
    "#     shift = shift[['mark','change']]\n",
    "#     shift.columns = ['lag_mark', 'lag_change']\n",
    "#     shift['lag_mark'] = shift['lag_mark'].where(~shift['lag_mark'].isna(), 'clear')\n",
    "#     df_err = pd.concat([df_err, shift], axis = 1)\n",
    "#     print(\"===============================err_part!done ::%s=================================\"%str(df_err.shape))\n",
    "#     return df_err\n",
    "\n",
    "# def output(df_err):\n",
    "#     global df0\n",
    "#     print(\"===============================output!start::%s=================================\"%str(df0.shape))\n",
    "\n",
    "#     dishes = list(df_err[(df_err['lag_mark'] != 'clear') \\\n",
    "#         & (df_err['change'] < 0)\n",
    "#         & (df_err['change'] != df_err['lag_change'])]['sku'].unique())\n",
    "#     print(\"===============================output!done::%s=================================\"%str((df0[df0['sku'].isin(dishes)]).shape))\n",
    "\n",
    "#     return df0[df0['sku'].isin(dishes)]\n",
    "\n",
    "# def check(sku):\n",
    "#     global df0\n",
    "#     a = df0[df0['sku'].isin(sku)].sort_values(['sku','received_date'])\n",
    "#     print(\"===============================check!done::%s=================================\"%str(a.shape))\n",
    "\n",
    "#     return a \n",
    "\n",
    "# def ou_level_lock_codes(lock_code_to_eliminate):\n",
    "#     \"\"\"\n",
    "#     正则. lock_code 需要被排除的, 依赖view表格. \n",
    "#     \"\"\" \n",
    "#     print(\"===========================ou_level_lock_codes!start!code :: %s=============================\"%str(code))\n",
    "#     select_none_lock  = pd.DataFrame(\n",
    "#         view.groupby('sku')[\n",
    "#             'mark'\n",
    "#             ].apply(list).astype(str).str.match('.+may')\n",
    "#         ).reset_index()\n",
    "\n",
    "#     select_none_lock2 = pd.DataFrame(\n",
    "#         view.groupby('sku')[\n",
    "#             'lock_codes'\n",
    "#             ].apply(list).astype(str).str.match('.+'+lock_code_to_eliminate)\n",
    "#         ).reset_index()\n",
    "#     # 去重    \n",
    "#     bose_err_list = set(select_none_lock[~select_none_lock['mark']]['sku'].unique())\n",
    "#     bose_err_list2 = list(select_none_lock2[~select_none_lock2['lock_codes']]['sku'].unique())\n",
    "#     bose_err_list = list(bose_err_list.intersection(bose_err_list2))\n",
    "#     bose_err_list = list(set(bose_err_list))\n",
    "#     print(\"===========================ou_level_lock_codes!done :: %s===============================\"%str(bose_err_list))\n",
    "\n",
    "#     return bose_err_list\n",
    "\n",
    "\n",
    "# # def printt(df):\n",
    "# #     print('{note:=>50}'.format(note=\"shape\") + '{note:=>50}'.format(note=df.shape))\n",
    "# #     print(df.info())\n",
    "\n",
    "# # # df.columns\n",
    "\n",
    "# out_df = pd.DataFrame()\n",
    "# for ou_code0 in df9['ou_code'].unique():\n",
    "\n",
    "#     bose_inv = load_data(ou_code0)[0]\n",
    "#     code = load_data(ou_code0)[1]\n",
    "    \n",
    "#     print('{note:=>50}'.format(note=ou_code0) + '{note:=>50}'.format(note=''))\n",
    "#     print(\"===============================this_code: %s=================================\"%ou_code0)\n",
    "#     print(\"===============================this_code_lock_code: %s=================================\"%code)\n",
    "\n",
    "\n",
    "#     print(\"============================boseInv before snap==============================\")\n",
    "#     print(bose_inv.info())\n",
    "\n",
    "#     df0 = snapshot()\n",
    "#     print(df0.info())\n",
    "#     df_err = err_part()\n",
    "\n",
    "#     view = output(df_err)\n",
    "#     bose_err_list = ou_level_lock_codes(code)\n",
    "#     bose_definite_wrong = check(bose_err_list)\n",
    "#     print(\"===============================~definite_wrong~=================================\")\n",
    "#     print(bose_definite_wrong.info())\n",
    "#     out_df = pd.concat([out_df, bose_definite_wrong], axis = 0)\n",
    "#     print(out_df.shape)\n",
    "\n",
    "# print(\"===============================~loop_done~=================================\")\n",
    "# print(out_df.shape)\n",
    "# print(\"===============================~'out_df.columns'~=================================\")\n",
    "# scan_len = 8\n",
    "# out_df['start_week'] = fridays[0]\n",
    "# out_df['end_week'] = fridays[-1]\n",
    "# out_df.columns = [\n",
    "#     str(j) + '_' + str(i) for i,j in enumerate(np.repeat('week', scan_len))\n",
    "#     ] + [\n",
    "#     'received_date','sku','mark','lock_codes',\n",
    "#     'wms_warehouse_id','fifo_fefo','location','ou_code', 'start_of_week', 'end_of_week'\n",
    "# ]\n",
    "# out_df['inc_day'] = df9['inc_day'].max()\n",
    "# out_df['location'] = [','.join(i) for i in out_df['location'] ]\n",
    "# out_df['received_date'] = out_df['received_date'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['create_date'].iloc[0] = 'abc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pd.to_datetime(df['create_date'].iloc[1:]).dtypes in ('<M8[ns]', np.datetime64):\n",
    "#     print('datetime')\n",
    "# else:\n",
    "#     print('error')\n",
    "# # df['create_date'].dtypes == np.object0\n",
    "# df['create_date'].str.match('(\\d{4}\\-\\d{2}\\-\\d{2})')\n",
    "# # df['create_date']\n",
    "# try:\n",
    "#     np.issubdtype(pd.to_datetime(df['create_date']), np.datetime64)\n",
    "#     print('true')\n",
    "# except:\n",
    "#     print('error')\n",
    "# # .fillna(pd.NaT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.query('sku_code == 2794452')[['lock_codes', 'inc_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_df[out_df['ou_code'] == 'COSTASHHTS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    120902.000000\n",
      "mean         56.453268\n",
      "std         366.158393\n",
      "min           0.000000\n",
      "25%           1.000000\n",
      "50%           7.000000\n",
      "75%          36.000000\n",
      "max       20200.000000\n",
      "Name: on_hand_qty, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_code</th>\n",
       "      <th>recived_date</th>\n",
       "      <th>lock_codes</th>\n",
       "      <th>inc_day</th>\n",
       "      <th>wms_warehouse_id</th>\n",
       "      <th>fifo_fefo</th>\n",
       "      <th>qty</th>\n",
       "      <th>location</th>\n",
       "      <th>ou_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6255</th>\n",
       "      <td>2804615</td>\n",
       "      <td>2013-12-30</td>\n",
       "      <td>Available</td>\n",
       "      <td>20211227</td>\n",
       "      <td>C21</td>\n",
       "      <td>fifo</td>\n",
       "      <td>49.0</td>\n",
       "      <td>{BRSB90516}</td>\n",
       "      <td>SIEMESUEPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>2798957</td>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>Available</td>\n",
       "      <td>20211227</td>\n",
       "      <td>C21</td>\n",
       "      <td>fifo</td>\n",
       "      <td>38.0</td>\n",
       "      <td>{BRSB70619}</td>\n",
       "      <td>SIEMESUEPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3602</th>\n",
       "      <td>2798957</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>Available</td>\n",
       "      <td>20211227</td>\n",
       "      <td>C21</td>\n",
       "      <td>fifo</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{CM1AT0227}</td>\n",
       "      <td>SIEMESUEPS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sku_code recived_date lock_codes   inc_day wms_warehouse_id fifo_fefo  \\\n",
       "6255   2804615   2013-12-30  Available  20211227              C21      fifo   \n",
       "3601   2798957   2016-12-28  Available  20211227              C21      fifo   \n",
       "3602   2798957   2017-03-20  Available  20211227              C21      fifo   \n",
       "\n",
       "       qty     location     ou_code  \n",
       "6255  49.0  {BRSB90516}  SIEMESUEPS  \n",
       "3601  38.0  {BRSB70619}  SIEMESUEPS  \n",
       "3602  20.0  {CM1AT0227}  SIEMESUEPS  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df9\n",
    "df = df[df['ou_code'].astype(str) == 'SIEMESUEPS']\n",
    "\n",
    "def fifo_fefo(df, type):\n",
    "    if type == 'fifo':\n",
    "        df['recived_date'] = pd.to_datetime(df['recived_date'])\n",
    "        df['fifo_fefo'] = 'fifo'\n",
    "    elif type == 'fefo':\n",
    "        df['recived_date'] = pd.to_datetime(df['expiration_date'].str.slice(0,10))\n",
    "        df['fifo_fefo'] = 'fefo'\n",
    "    else: \n",
    "        pass\n",
    "    return df \n",
    "df = fifo_fefo(df, 'fifo')\n",
    "df = df[['wms_warehouse_id','sku_code', 'sku_name', 'sku_desc', 'location',\\\n",
    "        'lock_codes', 'on_hand_qty', 'in_transit_qty','allocated_qty', \n",
    "        'recived_date','usage_flag', 'fifo_fefo','inc_day', 'ou_code']]\n",
    "df['qty'] = df['on_hand_qty']\n",
    "\n",
    "print(df['on_hand_qty'].describe())\n",
    "\n",
    "df = df.sort_values(['sku_code', 'recived_date']).groupby(\n",
    "    ['recived_date', 'sku_code', 'lock_codes','inc_day', 'wms_warehouse_id', 'fifo_fefo'],\n",
    "    dropna = False\n",
    "    ).agg(\n",
    "{\n",
    "    'qty':'sum',\n",
    "    'location': set\n",
    "    # ? 这里如果group by location德华会有问题, 列数,miasjdijaisjd\n",
    "}\n",
    ").sort_values(['sku_code', 'recived_date']).reset_index()\n",
    "# 只选择有多个收货日期的货物\n",
    "filter0 = df.groupby(['sku_code'])['recived_date'].agg(\n",
    "{\n",
    "    set\n",
    "}\n",
    "    ).reset_index()\n",
    "\n",
    "filter0 = pd.DataFrame(filter0[(filter0['set'].apply(len)) > 1]['sku_code'].drop_duplicates())\n",
    "bose_inv = filter0.merge(df, on = ['sku_code'], how = 'inner')\\\n",
    "        .sort_values(['recived_date','sku_code', 'inc_day'])\n",
    "ou_code = 'SIEMESUEPS'\n",
    "bose_inv['ou_code'] = ou_code\n",
    "bose_inv.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_code</th>\n",
       "      <th>recived_date</th>\n",
       "      <th>lock_codes</th>\n",
       "      <th>inc_day</th>\n",
       "      <th>wms_warehouse_id</th>\n",
       "      <th>fifo_fefo</th>\n",
       "      <th>qty</th>\n",
       "      <th>location</th>\n",
       "      <th>ou_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6255</th>\n",
       "      <td>2804615</td>\n",
       "      <td>2013-12-30</td>\n",
       "      <td>Available</td>\n",
       "      <td>20211227</td>\n",
       "      <td>C21</td>\n",
       "      <td>fifo</td>\n",
       "      <td>49.0</td>\n",
       "      <td>{BRSB90516}</td>\n",
       "      <td>SIEMESUEPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>2798957</td>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>Available</td>\n",
       "      <td>20211227</td>\n",
       "      <td>C21</td>\n",
       "      <td>fifo</td>\n",
       "      <td>38.0</td>\n",
       "      <td>{BRSB70619}</td>\n",
       "      <td>SIEMESUEPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3602</th>\n",
       "      <td>2798957</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>Available</td>\n",
       "      <td>20211227</td>\n",
       "      <td>C21</td>\n",
       "      <td>fifo</td>\n",
       "      <td>20.0</td>\n",
       "      <td>{CM1AT0227}</td>\n",
       "      <td>SIEMESUEPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>2798957</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>Available</td>\n",
       "      <td>20211227</td>\n",
       "      <td>C21</td>\n",
       "      <td>fifo</td>\n",
       "      <td>15.0</td>\n",
       "      <td>{CRSAA0713}</td>\n",
       "      <td>SIEMESUEPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>2798398</td>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>Available</td>\n",
       "      <td>20211227</td>\n",
       "      <td>C21</td>\n",
       "      <td>fifo</td>\n",
       "      <td>15.0</td>\n",
       "      <td>{CM3AD0636}</td>\n",
       "      <td>SIEMESUEPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23498</th>\n",
       "      <td>5687445</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Available</td>\n",
       "      <td>20220103</td>\n",
       "      <td>C21</td>\n",
       "      <td>fifo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{BFH0005}</td>\n",
       "      <td>SIEMESUEPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23500</th>\n",
       "      <td>5687447</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Available</td>\n",
       "      <td>20220103</td>\n",
       "      <td>C21</td>\n",
       "      <td>fifo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{BFH0005}</td>\n",
       "      <td>SIEMESUEPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23502</th>\n",
       "      <td>5687459</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Available</td>\n",
       "      <td>20220103</td>\n",
       "      <td>C21</td>\n",
       "      <td>fifo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{CRHBE0326}</td>\n",
       "      <td>SIEMESUEPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23504</th>\n",
       "      <td>5690844</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Available</td>\n",
       "      <td>20220103</td>\n",
       "      <td>C21</td>\n",
       "      <td>fifo</td>\n",
       "      <td>3.0</td>\n",
       "      <td>{CM2AU0636, CM2AU0535, CM3AC0441}</td>\n",
       "      <td>SIEMESUEPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23506</th>\n",
       "      <td>5693071</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Available</td>\n",
       "      <td>20220103</td>\n",
       "      <td>C21</td>\n",
       "      <td>fifo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{nan}</td>\n",
       "      <td>SIEMESUEPS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23527 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku_code recived_date lock_codes   inc_day wms_warehouse_id fifo_fefo  \\\n",
       "6255    2804615   2013-12-30  Available  20211227              C21      fifo   \n",
       "3601    2798957   2016-12-28  Available  20211227              C21      fifo   \n",
       "3602    2798957   2017-03-20  Available  20211227              C21      fifo   \n",
       "3603    2798957   2017-04-28  Available  20211227              C21      fifo   \n",
       "3323    2798398   2017-06-23  Available  20211227              C21      fifo   \n",
       "...         ...          ...        ...       ...              ...       ...   \n",
       "23498   5687445          NaT  Available  20220103              C21      fifo   \n",
       "23500   5687447          NaT  Available  20220103              C21      fifo   \n",
       "23502   5687459          NaT  Available  20220103              C21      fifo   \n",
       "23504   5690844          NaT  Available  20220103              C21      fifo   \n",
       "23506   5693071          NaT  Available  20220103              C21      fifo   \n",
       "\n",
       "        qty                           location     ou_code  \n",
       "6255   49.0                        {BRSB90516}  SIEMESUEPS  \n",
       "3601   38.0                        {BRSB70619}  SIEMESUEPS  \n",
       "3602   20.0                        {CM1AT0227}  SIEMESUEPS  \n",
       "3603   15.0                        {CRSAA0713}  SIEMESUEPS  \n",
       "3323   15.0                        {CM3AD0636}  SIEMESUEPS  \n",
       "...     ...                                ...         ...  \n",
       "23498   1.0                          {BFH0005}  SIEMESUEPS  \n",
       "23500   1.0                          {BFH0005}  SIEMESUEPS  \n",
       "23502   1.0                        {CRHBE0326}  SIEMESUEPS  \n",
       "23504   3.0  {CM2AU0636, CM2AU0535, CM3AC0441}  SIEMESUEPS  \n",
       "23506   0.0                              {nan}  SIEMESUEPS  \n",
       "\n",
       "[23527 rows x 9 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bose_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hah, mutated\n",
      "snap_df0_column before in snap Index([20211227, 'sku_code', 'received_date', 'sku'], dtype='object') len of df0 in snap (11542, 4)\n",
      "   20211227  sku_code received_date  sku\n",
      "0      49.0   2804615    2013-12-30  NaN\n",
      "1      38.0   2798957    2016-12-28  NaN\n",
      "2      20.0   2798957    2017-03-20  NaN\n",
      "3      15.0   2798957    2017-04-28  NaN\n",
      "4      15.0   2798398    2017-06-23  NaN\n",
      "auto fill enabled , ncol is: 6\n",
      "   20211227  20211227  20211227  20211227  20211227  20211227\n",
      "0      49.0      49.0      49.0      49.0      49.0      49.0\n",
      "1      38.0      38.0      38.0      38.0      38.0      38.0\n",
      "2      20.0      20.0      20.0      20.0      20.0      20.0\n",
      "3      15.0      15.0      15.0      15.0      15.0      15.0\n",
      "4      15.0      15.0      15.0      15.0      15.0      15.0\n",
      "   20211227  20211227  20211227  20211227  20211227  20211227  20211227  \\\n",
      "0      49.0      49.0      49.0      49.0      49.0      49.0      49.0   \n",
      "1      38.0      38.0      38.0      38.0      38.0      38.0      38.0   \n",
      "2      20.0      20.0      20.0      20.0      20.0      20.0      20.0   \n",
      "3      15.0      15.0      15.0      15.0      15.0      15.0      15.0   \n",
      "4      15.0      15.0      15.0      15.0      15.0      15.0      15.0   \n",
      "\n",
      "   sku_code received_date  sku  \n",
      "0   2804615    2013-12-30  NaN  \n",
      "1   2798957    2016-12-28  NaN  \n",
      "2   2798957    2017-03-20  NaN  \n",
      "3   2798957    2017-04-28  NaN  \n",
      "4   2798398    2017-06-23  NaN  \n",
      "     11    12    13    14    15    16  20211227  sku_code received_date  sku\n",
      "0  49.0  49.0  49.0  49.0  49.0  49.0      49.0   2804615    2013-12-30  NaN\n",
      "1  38.0  38.0  38.0  38.0  38.0  38.0      38.0   2798957    2016-12-28  NaN\n",
      "2  20.0  20.0  20.0  20.0  20.0  20.0      20.0   2798957    2017-03-20  NaN\n",
      "3  15.0  15.0  15.0  15.0  15.0  15.0      15.0   2798957    2017-04-28  NaN\n",
      "4  15.0  15.0  15.0  15.0  15.0  15.0      15.0   2798398    2017-06-23  NaN\n",
      "===========================snap!done for : [nan]=============================\n"
     ]
    }
   ],
   "source": [
    "df0 = pd.DataFrame()\n",
    "df0 = snapshot()\n",
    "# for i in bose_inv['sku_code'].unique():\n",
    "#     df_out = bose_inv[bose_inv['sku_code'] == i]\\\n",
    "#         .pivot_table(columns='inc_day', index = 'recived_date', values='qty').reset_index()\n",
    "#     df_out['sku_code'] = i\n",
    "#     df0 = pd.concat([df0, df_out], axis = 0)\n",
    "# try:\n",
    "#     df0.columns = df0.columns.get_level_values(level=1)\n",
    "# except:\n",
    "#     pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>20211227</th>\n",
       "      <th>sku_code</th>\n",
       "      <th>received_date</th>\n",
       "      <th>sku</th>\n",
       "      <th>mark</th>\n",
       "      <th>lock_codes</th>\n",
       "      <th>wms_warehouse_id</th>\n",
       "      <th>fifo_fefo</th>\n",
       "      <th>location</th>\n",
       "      <th>ou_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2815069</td>\n",
       "      <td>2018-09-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3027837</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2851362</td>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2808937</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2799097</td>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11537</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2919472</td>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11538</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2960557</td>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11539</th>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5542535</td>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11540</th>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>5570064</td>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11541</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5693073</td>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11542 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          11     12     13     14     15     16  20211227  sku_code  \\\n",
       "0        0.0    0.0    0.0    0.0    0.0    0.0       0.0   2815069   \n",
       "1        0.0    0.0    0.0    0.0    0.0    0.0       0.0   3027837   \n",
       "2        1.0    1.0    1.0    1.0    1.0    1.0       1.0   2851362   \n",
       "3        1.0    1.0    1.0    1.0    1.0    1.0       1.0   2808937   \n",
       "4        0.0    0.0    0.0    0.0    0.0    0.0       0.0   2799097   \n",
       "...      ...    ...    ...    ...    ...    ...       ...       ...   \n",
       "11537    1.0    1.0    1.0    1.0    1.0    1.0       1.0   2919472   \n",
       "11538    5.0    5.0    5.0    5.0    5.0    5.0       5.0   2960557   \n",
       "11539   72.0   72.0   72.0   72.0   72.0   72.0      72.0   5542535   \n",
       "11540  140.0  140.0  140.0  140.0  140.0  140.0     140.0   5570064   \n",
       "11541    2.0    2.0    2.0    2.0    2.0    2.0       2.0   5693073   \n",
       "\n",
       "      received_date  sku mark lock_codes wms_warehouse_id fifo_fefo location  \\\n",
       "0        2018-09-29  1.0  new        NaN              NaN       NaN      NaN   \n",
       "1        2020-06-17  1.0  new        NaN              NaN       NaN      NaN   \n",
       "2        2020-10-10  1.0    0        NaN              NaN       NaN      NaN   \n",
       "3        2020-11-03  1.0    0        NaN              NaN       NaN      NaN   \n",
       "4        2020-11-06  1.0  new        NaN              NaN       NaN      NaN   \n",
       "...             ...  ...  ...        ...              ...       ...      ...   \n",
       "11537    2021-12-27  0.0    0        NaN              NaN       NaN      NaN   \n",
       "11538    2021-12-27  0.0    0        NaN              NaN       NaN      NaN   \n",
       "11539    2021-12-27  0.0    0        NaN              NaN       NaN      NaN   \n",
       "11540    2021-12-27  0.0    0        NaN              NaN       NaN      NaN   \n",
       "11541    2021-12-27  0.0    0        NaN              NaN       NaN      NaN   \n",
       "\n",
       "      ou_code  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "...       ...  \n",
       "11537     NaN  \n",
       "11538     NaN  \n",
       "11539     NaN  \n",
       "11540     NaN  \n",
       "11541     NaN  \n",
       "\n",
       "[11542 rows x 16 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.query('lock_codes.isnull()', engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bose_inv.groupby(['sku_code', 'inc_day'])['lock_codes'].set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.iloc[:, 0:7].isna().sum(axis = 1) == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = output(df_err)\n",
    "view['sku'].unique()\n",
    "# bose_err_list = ou_level_lock_codes(code)\n",
    "# bose_definite_wrong = check(bose_err_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bose_err_list = ou_level_lock_codes(code)\n",
    "bose_definite_wrong = check(bose_err_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_code_to_eliminate = 'QX'\n",
    "select_none_lock  = pd.DataFrame(\n",
    "    view.groupby('sku')[\n",
    "        'mark'\n",
    "        ].apply(list).astype(str).str.match('.+may')\n",
    "    ).reset_index()\n",
    "\n",
    "select_none_lock2 = pd.DataFrame(\n",
    "    view.groupby('sku')[\n",
    "        'lock_codes'\n",
    "        ].apply(list).astype(str).str.match('.+'+lock_code_to_eliminate)\n",
    "    ).reset_index()\n",
    "# 去重    \n",
    "bose_err_list = set(select_none_lock['sku'].unique())\n",
    "bose_err_list2 = list(select_none_lock2[~select_none_lock2['lock_codes']]['sku'].unique())\n",
    "bose_err_list = list(bose_err_list.intersection(bose_err_list2))\n",
    "bose_err_list = list(set(bose_err_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bose_err_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ou_level_lock_codes(lock_code_to_eliminate):\n",
    "    \"\"\"\n",
    "    正则. lock_code 需要被排除的, 依赖view表格. \n",
    "    \"\"\" \n",
    "    print(\"===========================ou_level_lock_codes!start!code :: %s=============================\"%str(code))\n",
    "    select_none_lock  = pd.DataFrame(\n",
    "        view.groupby('sku')[\n",
    "            'mark'\n",
    "            ].apply(list).astype(str).str.match('.+may')\n",
    "        ).reset_index()\n",
    "\n",
    "    select_none_lock2 = pd.DataFrame(\n",
    "        view.groupby('sku')[\n",
    "            'lock_codes'\n",
    "            ].apply(list).astype(str).str.match('.+'+lock_code_to_eliminate)\n",
    "        ).reset_index()\n",
    "    # 去重    \n",
    "    bose_err_list = set(select_none_lock[~select_none_lock['mark']]['sku'].unique())\n",
    "    bose_err_list2 = list(select_none_lock2[~select_none_lock2['lock_codes']]['sku'].unique())\n",
    "    bose_err_list = list(bose_err_list.intersection(bose_err_list2))\n",
    "    bose_err_list = list(set(bose_err_list))\n",
    "    print(\"===========================ou_level_lock_codes!done :: %s===============================\"%str(bose_err_list))\n",
    "\n",
    "    return bose_err_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "        df0 = snapshot()\n",
    "        print(df0.info())\n",
    "        df_err = err_part()\n",
    "\n",
    "        view = output(df_err)\n",
    "        bose_err_list = ou_level_lock_codes(code)\n",
    "        bose_definite_wrong = check(bose_err_list)\n",
    "        print(\"===============================~definite_wrong~=================================\")\n",
    "        print(bose_definite_wrong.info())\n",
    "        out_df = pd.concat([out_df, bose_definite_wrong], axis = 0)\n",
    "        print(out_df.shape)\n",
    "    except: \n",
    "        print('None data for code ::: %s :::'%ou_code0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(ou_code):\n",
    "    \"\"\"\n",
    "    load bose data;\n",
    "    所有类型的qty都要加起来哦\n",
    "    只选择有多个收货日期的货物\n",
    "    \"\"\"\n",
    "    global code, df, bose_inv, df0 \n",
    "    df0 = pd.DataFrame()\n",
    "    df = df9\n",
    "    df = df[df['ou_code'].astype(str) == ou_code]\n",
    "\n",
    "    def fifo_fefo(df, type):\n",
    "        if type == 'fifo':\n",
    "            df['recived_date'] = pd.to_datetime(df['recived_date'])\n",
    "            df['fifo_fefo'] = 'fifo'\n",
    "        elif type == 'fefo':\n",
    "            df['recived_date'] = pd.to_datetime(df['expiration_date'].str.slice(0,10))\n",
    "            df['fifo_fefo'] = 'fefo'\n",
    "        else: \n",
    "            pass\n",
    "        return df \n",
    "\n",
    "    if ou_code in {'HPPXXWHWDS', 'HPPXXSHMGS'}:\n",
    "        # hp wh\n",
    "        print(\"load_data\", \" 'HPPXXWHWDS', 'HPPXXSHMGS' \")\n",
    "        code = '(QH|27|QI)'\n",
    "        df = fifo_fefo(df, 'fifo')\n",
    "\n",
    "    elif ou_code in {'MICHETCTGS', 'MICHESHXCS'}:\n",
    "        print(\"load_data\", \" 'MICHETCTGS', 'MICHESHXCS' \")\n",
    "        df = df[df['expiration_date'] != '4712-12-31']\n",
    "        # mich tc, rt,m  FEFO\n",
    "        code = '(BLOCKED_TH|RETURN)'\n",
    "        print(\"mich_if_if\")\n",
    "        df = fifo_fefo(df, 'fefo')\n",
    "\n",
    "    elif ou_code == 'COSTASHHTS':\n",
    "        # COSTASHHTS expiration_date 没有空值.\n",
    "        df1 = df[df['expiration_date'] == '4712-12-31'] # fifo @# scale datetime. need redefine when other wms sys/..\n",
    "        df2 = df[df['expiration_date'] != '4712-12-31'] # fefo\n",
    "        df1 = fifo_fefo(df1, 'fifo')\n",
    "        df2 = fifo_fefo(df2, 'fefo')\n",
    "        df = pd.concat([df1, df2], axis = 0)\n",
    "        code = '(blocked)'\n",
    "        # wmos\n",
    "    else:\n",
    "        \n",
    "        # make a date\n",
    "        make_day = str(int(date.today().strftime('%Y')) + 50)+'-09-09'\n",
    "        df1 = df[df['expiration_date'] == '9999-09-09'] # fifo @# scale datetime. need redefine when other wms sys/..\n",
    "        df2 = df[df['expiration_date'] <= make_day] # fefo\n",
    "        df1 = fifo_fefo(df1, 'fifo')\n",
    "        df2 = fifo_fefo(df2, 'fefo')\n",
    "        df = pd.concat([df1, df2], axis = 0)\n",
    "        # code = '(\\w)' # 不知道为什么这种方法不对, 但没时间调试了.\n",
    "        code = \"(PP|PV|BL|BA|QH|QX|LC|DW|PO|PT|DT|LW|PZ|PS)\"\n",
    "\n",
    "\n",
    "    # print(code)\n",
    "    \n",
    "    \n",
    "    df = df[['wms_warehouse_id','sku_code', 'sku_name', 'sku_desc', 'location',\\\n",
    "        'lock_codes', 'on_hand_qty', 'in_transit_qty','allocated_qty', \n",
    "        'recived_date','usage_flag', 'fifo_fefo','inc_day', 'ou_code']]\n",
    "    df['qty'] = df['on_hand_qty']\n",
    "    \n",
    "    \n",
    "    # 没有重复的 目前看....aaa\n",
    "    print(\"===============================oucode :: %s=================================\"%df['ou_code'].unique())\n",
    "    print(df['on_hand_qty'].describe())\n",
    "\n",
    "    df = df.sort_values(['sku_code', 'recived_date']).groupby(\n",
    "        ['recived_date', 'sku_code', 'lock_codes','inc_day', 'wms_warehouse_id', 'fifo_fefo'],\n",
    "        # dropna = False\n",
    "        ).agg(\n",
    "    {\n",
    "        'qty':'sum',\n",
    "        'location': set\n",
    "        # ? 这里如果group by location德华会有问题, 列数,miasjdijaisjd\n",
    "    }\n",
    "    ).sort_values(['sku_code', 'recived_date']).reset_index()\n",
    "    # 只选择有多个收货日期的货物\n",
    "    filter0 = df.groupby(['sku_code'])['recived_date'].agg(\n",
    "    {\n",
    "        set\n",
    "    }\n",
    "        ).reset_index()\n",
    "\n",
    "    filter0 = pd.DataFrame(filter0[(filter0['set'].apply(len)) > 1]['sku_code'].drop_duplicates())\n",
    "    bose_inv = filter0.merge(df, on = ['sku_code'], how = 'inner')\\\n",
    "        .sort_values(['recived_date','sku_code', 'inc_day'])\n",
    "    bose_inv['ou_code'] = ou_code\n",
    "    print(bose_inv.head())\n",
    "    return bose_inv, code\n",
    "\n",
    "def snapshot():\n",
    "    \"\"\"\n",
    "    pivot table. inc_day 快照 作为 cols\n",
    "    添加标记.\n",
    "    \"\"\"\n",
    "    global df0, bose_inv\n",
    "    df0 = pd.DataFrame()\n",
    "    for i in tqdm(bose_inv['sku_code'].unique()):\n",
    "        df_out = bose_inv[bose_inv['sku_code'] == i]\\\n",
    "            .pivot_table(columns='inc_day', index = 'recived_date', values='qty').reset_index()\n",
    "        df_out['sku_code'] = i\n",
    "        df0 = pd.concat([df0, df_out], axis = 0)\n",
    "    try:\n",
    "        df0.columns = df0.columns.get_level_values(level=1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if re.search('(\\d+)', str(df0.columns[0])) == None:\n",
    "        df0.columns = ['received_date', df0.columns[1],  df0.columns[2], 'sku']\n",
    "        df0 = df0[[df0.columns[1], df0.columns[2], 'received_date', 'sku']]\n",
    "        print('hah, mutated')\n",
    "    else:\n",
    "        print('ha. no need mutations')\n",
    "        pass\n",
    "\n",
    "    # if test.columns[0]  == '':\n",
    "    #     test.columns = ['received_date', test.columns[1],  test.columns[2], 'sku']\n",
    "    #     test = test[[test.columns[1], test.columns[2], 'received_date', 'sku']]\n",
    "    # else:\n",
    "    #     pass\n",
    "    print(\"snap_df0_column before in snap\", df0.columns, \"len of df0 in snap\", (df0.shape))\n",
    "    df0 = df0.reset_index(drop = True) # 4 \n",
    "    print(df0.head())\n",
    "\n",
    "    # df0 = pd.DataFrame(np.zeros([3, 4]))\n",
    "    \"\"\"\n",
    "    添加缺失列\n",
    "    \"\"\"\n",
    "    if len(df0.columns) == 10:\n",
    "        print(list(df0.columns[0:8]))\n",
    "        df0.columns = list(df0.columns[0:8]) + ['received_date','sku']\n",
    "        print(\"normal process in snap::%s\"%str(df0.shape))\n",
    "    else:\n",
    "        # pass\n",
    "        print(\"auto fill enabled , ncol is: %s\" %(10 - len(df0.columns)))\n",
    "        # somelen = 10 - len(df0.columns)\n",
    "        # df_zero = pd.DataFrame(np.zeros([df0.shape[0], somelen]))\n",
    "        # df0 = pd.concat([df_zero, df0], axis = 1)\n",
    "        # df0.columns = list(\n",
    "        #     np.repeat(0, (somelen))\n",
    "        #     ) + list(\n",
    "        #         df0.columns[0:(scan_len)]\n",
    "        #         ) + ['received_date','sku']\n",
    "        names = df0.columns[0:2]\n",
    "        df_zero = pd.DataFrame(df0.iloc[:,0])\n",
    "        df_zero2 = pd.DataFrame()\n",
    "        # df_zero. copy()\n",
    "        for i in range(0,somelen):\n",
    "            df_zero2 = pd.concat([df_zero2, df_zero], axis = 1)\n",
    "\n",
    "        print(df_zero2.head())\n",
    "\n",
    "        df0 = pd.concat([df_zero2, df0], axis = 1)\n",
    "        print(df0.head())\n",
    "        df0.columns = list(range(11,11 + somelen)) + list(names) + ['received_date','sku']\n",
    "    scan_len = 8\n",
    "    print(df0.head())\n",
    "    df0 = df0.sort_values(['sku', 'received_date'])\n",
    "    df0['mark'] = 0\n",
    "  \n",
    "    # except:\n",
    "    df0['mark'] = np.where(df0.iloc[:, 6].isna() == True, 'new', df0['mark'])\n",
    "    df0['mark'] = np.where(df0.iloc[:, 7].isna() == True, 'clear', df0['mark'])\n",
    "        \n",
    "    \n",
    "    # fill na~\n",
    "    df0 = df0.fillna(0)\n",
    "    bose_inv = bose_inv.rename({'sku_code':'sku', 'recived_date':'received_date'}, axis = 1)\\\n",
    "        .reset_index(drop = True).drop(['inc_day', 'qty'], axis = 1)\n",
    "    bose_inv = bose_inv.drop_duplicates(subset = ['sku', 'received_date', 'lock_codes'])\n",
    "    df0 = df0.merge(bose_inv, on = ['sku','received_date'], how = 'left')\n",
    "\n",
    "    # may lock\n",
    "    df0['mark'] = df0['mark'].where(df0.iloc[:, 0:scan_len].fillna(0).nunique(axis = 1) > 1, 'may_lock')\n",
    "    print(\"===========================snap!done for : %s=============================\" %df0['ou_code'].unique())\n",
    "    return df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"===============================mid_function_check=================================\")\n",
    "def err_part():\n",
    "    \"\"\"\n",
    "    findout who are the naught peach.\n",
    "    err 中干掉了 new 干掉了maylock \n",
    "    \"\"\"\n",
    "    global df0\n",
    "\n",
    "    print(\"============================err_part!start: %s============================\"%str(df0.shape))\n",
    "    scan_len = 8\n",
    "    df_err = df0[df0['mark'] != 'new']\n",
    "    # 补充可能被锁的标记\n",
    "    # df_err['mark'] = df_err['mark'].where(df_err.iloc[:, 0:8].fillna(0).nunique(axis = 1) > 1, 'may_lock')\n",
    "    # 干掉了maylock\n",
    "    df_err = df_err[df_err['mark'] != 'may_lock'].sort_values(['sku', 'received_date'])\n",
    "    # print(\"===============================scan_len_err_function--%s=================================\"%scan_len)\n",
    "    # print(df_err.iloc[:,0:scan_len])\n",
    "    df_err['change'] = df_err.iloc[:,0:scan_len].diff(axis = 1).sum(axis = 1)\n",
    "    if str(df_err['ou_code'].unique()) in {'HPPXXWHWDS', 'HPPXXSHMGS'}:\n",
    "        shift = df_err.groupby(['sku', 'wms_warehouse_id', 'lock_code']).shift(1) \n",
    "    else:\n",
    "        shift = df_err.groupby(['sku', 'wms_warehouse_id']).shift(1) \n",
    "    shift = shift[['mark','change']]\n",
    "    shift.columns = ['lag_mark', 'lag_change']\n",
    "    shift['lag_mark'] = shift['lag_mark'].where(~shift['lag_mark'].isna(), 'clear')\n",
    "    df_err = pd.concat([df_err, shift], axis = 1)\n",
    "    print(\"===============================err_part!done ::%s=================================\"%str(df_err.shape))\n",
    "    return df_err\n",
    "\n",
    "def output(df_err):\n",
    "    global df0\n",
    "    print(\"===============================output!start::%s=================================\"%str(df0.shape))\n",
    "\n",
    "    dishes = list(df_err[(df_err['lag_mark'] != 'clear') \\\n",
    "        & (df_err['change'] < 0)\n",
    "        & (df_err['change'] != df_err['lag_change'])]['sku'].unique())\n",
    "    print(\"===============================output!done::%s=================================\"%str((df0[df0['sku'].isin(dishes)]).shape))\n",
    "\n",
    "    return df0[df0['sku'].isin(dishes)]\n",
    "\n",
    "def check(sku):\n",
    "    global df0\n",
    "    a = df0[df0['sku'].isin(sku)].sort_values(['sku','received_date'])\n",
    "    print(\"===============================check!done::%s=================================\"%str(a.shape))\n",
    "\n",
    "    return a \n",
    "\n",
    "def ou_level_lock_codes(lock_code_to_eliminate):\n",
    "    \"\"\"\n",
    "    正则. lock_code 需要被排除的, 依赖view表格. \n",
    "    \"\"\" \n",
    "    print(\"===========================ou_level_lock_codes!start!code :: %s=============================\"%str(code))\n",
    "    select_none_lock  = pd.DataFrame(\n",
    "        view.groupby('sku')[\n",
    "            'mark'\n",
    "            ].apply(list).astype(str).str.match('.+may')\n",
    "        ).reset_index()\n",
    "\n",
    "    select_none_lock2 = pd.DataFrame(\n",
    "        view.groupby('sku')[\n",
    "            'lock_codes'\n",
    "            ].apply(list).astype(str).str.match('.+'+lock_code_to_eliminate)\n",
    "        ).reset_index()\n",
    "    # 去重    \n",
    "    bose_err_list = set(select_none_lock[~select_none_lock['mark']]['sku'].unique())\n",
    "    bose_err_list2 = list(select_none_lock2[~select_none_lock2['lock_codes']]['sku'].unique())\n",
    "    bose_err_list = list(bose_err_list.intersection(bose_err_list2))\n",
    "    bose_err_list = list(set(bose_err_list))\n",
    "    print(\"===========================ou_level_lock_codes!done :: %s===============================\"%str(bose_err_list))\n",
    "\n",
    "    return bose_err_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df9['ou_code'].unique()\n",
    "bose_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ou_code0 = 'SIEMESUEPS'\n",
    "bose_inv = load_data(ou_code0)[0]\n",
    "code = load_data(ou_code0)[1]\n",
    "#??????shabi?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame()\n",
    "for i in bose_inv['sku_code'].unique():\n",
    "    df_out = bose_inv[bose_inv['sku_code'] == i]\\\n",
    "        .pivot_table(columns='inc_day', index = 'recived_date', values='qty').reset_index()\n",
    "    df_out['sku_code'] = i\n",
    "    df0 = pd.concat([df0, df_out], axis = 0)\n",
    "try:\n",
    "    df0.columns = df0.columns.get_level_values(level=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if re.search('(\\d+)', str(df0.columns[0])) == None:\n",
    "    df0.columns = ['received_date', df0.columns[1],  df0.columns[2], 'sku']\n",
    "    df0 = df0[[df0.columns[1], df0.columns[2], 'received_date', 'sku']]\n",
    "    print('hah, mutated')\n",
    "else:\n",
    "    print('ha. no need mutations')\n",
    "    pass\n",
    "\n",
    "# if test.columns[0]  == '':\n",
    "#     test.columns = ['received_date', test.columns[1],  test.columns[2], 'sku']\n",
    "#     test = test[[test.columns[1], test.columns[2], 'received_date', 'sku']]\n",
    "# else:\n",
    "#     pass\n",
    "print(\"snap_df0_column before in snap\", df0.columns, \"len of df0 in snap\", (df0.shape))\n",
    "df0 = df0.reset_index(drop = True) # 4 \n",
    "print(df0.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "break #!@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df0 = pd.DataFrame(np.zeros([3, 4]))\n",
    "\"\"\"\n",
    "添加缺失列\n",
    "\"\"\"\n",
    "if len(df0.columns) == 10:\n",
    "    print(list(df0.columns[0:8]))\n",
    "    df0.columns = list(df0.columns[0:8]) + ['received_date','sku']\n",
    "    print(\"normal process in snap::%s\"%str(df0.shape))\n",
    "else:\n",
    "    # pass\n",
    "    print(\"auto fill enabled , ncol is: %s\" %(10 - len(df0.columns)))\n",
    "    # somelen = 10 - len(df0.columns)\n",
    "    # df_zero = pd.DataFrame(np.zeros([df0.shape[0], somelen]))\n",
    "    # df0 = pd.concat([df_zero, df0], axis = 1)\n",
    "    # df0.columns = list(\n",
    "    #     np.repeat(0, (somelen))\n",
    "    #     ) + list(\n",
    "    #         df0.columns[0:(scan_len)]\n",
    "    #         ) + ['received_date','sku']\n",
    "    names = df0.columns[0:2]\n",
    "    df_zero = pd.DataFrame(df0.iloc[:,0])\n",
    "    df_zero2 = pd.DataFrame()\n",
    "    # df_zero. copy()\n",
    "    for i in range(0,somelen):\n",
    "        df_zero2 = pd.concat([df_zero2, df_zero], axis = 1)\n",
    "\n",
    "    print(df_zero2.head())\n",
    "\n",
    "    df0 = pd.concat([df_zero2, df0], axis = 1)\n",
    "    print(df0.head())\n",
    "    df0.columns = list(range(11,11 + somelen)) + list(names) + ['received_date','sku']\n",
    "scan_len = 8\n",
    "print(df0.head())\n",
    "\n",
    "\n",
    "df0 = df0.sort_values(['sku', 'received_date'])\n",
    "df0['mark'] = 0\n",
    "df0['mark'] = df0['mark'].where(\n",
    "    df0.iloc[:,  (scan_len - 1)].isna() == False, 'new')\n",
    "    # df0.iloc[:, 0: (scan_len - 1)].isna().all(axis = 1) == False, 'new')\n",
    "    # \n",
    "df0['mark'] = df0['mark'].where(\n",
    "    ~df0.iloc[:,(scan_len - 1)].isna() , 'clear')\n",
    "# fill na~\n",
    "df0 = df0.fillna(0)\n",
    "bose_inv = bose_inv.rename({'sku_code':'sku', 'recived_date':'received_date'}, axis = 1)\\\n",
    "    .reset_index(drop = True).drop(['inc_day', 'qty'], axis = 1)\n",
    "bose_inv = bose_inv.drop_duplicates(subset = ['sku', 'received_date', 'lock_codes'])\n",
    "df0 = df0.merge(bose_inv, on = ['sku','received_date'], how = 'left')\n",
    "\n",
    "# may lock\n",
    "df0['mark'] = df0['mark'].where(df0.iloc[:, 0:scan_len].fillna(0).nunique(axis = 1) > 1, 'may_lock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_df = pd.DataFrame()\n",
    "for ou_code0 in df9['ou_code'].unique():\n",
    "\n",
    "    bose_inv = load_data(ou_code0)[0]\n",
    "    code = load_data(ou_code0)[1]\n",
    "    \n",
    "    print('{note:=>50}'.format(note=ou_code0) + '{note:=>50}'.format(note=''))\n",
    "    print(\"===============================this_code: %s=================================\"%ou_code0)\n",
    "    print(\"===============================this_code_lock_code: %s=================================\"%code)\n",
    "\n",
    "\n",
    "    print(\"============================boseInv before snap==============================\")\n",
    "    print(bose_inv.info())\n",
    "\n",
    "    try: \n",
    "        df0 = snapshot()\n",
    "        print(df0.info())\n",
    "        df_err = err_part()\n",
    "\n",
    "        view = output(df_err)\n",
    "        bose_err_list = ou_level_lock_codes(code)\n",
    "        bose_definite_wrong = check(bose_err_list)\n",
    "        print(\"===============================~definite_wrong~=================================\")\n",
    "        print(bose_definite_wrong.info())\n",
    "        out_df = pd.concat([out_df, bose_definite_wrong], axis = 0)\n",
    "        print(out_df.shape)\n",
    "    except: \n",
    "        print('None data for code ::: %s :::'%ou_code0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bose_inv.loc[:, 'lock_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    bose_inv.groupby('sku_code')[\n",
    "        'lock_codes'\n",
    "        ].apply(list).astype(str).str.match('.+'+'(\\w)')\n",
    "    ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search('(\\d+)', str(test.columns[0])) == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test.columns[0]  == '':\n",
    "            test.columns = ['received_date', test.columns[1],  test.columns[2], 'sku']\n",
    "            test = test[[test.columns[1], test.columns[2], 'received_date', 'sku']]\n",
    "else:\n",
    "    print('ha. noneed mutations')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snapshot():\n",
    "    \"\"\"\n",
    "    pivot table. inc_day 快照 作为 cols\n",
    "    添加标记.\n",
    "    \"\"\"\n",
    "    global df0, bose_inv\n",
    "    df0 = pd.DataFrame()\n",
    "    for i in bose_inv['sku_code'].unique():\n",
    "        df_out = bose_inv[bose_inv['sku_code'] == i]\\\n",
    "            .pivot_table(columns=['inc_day'], index = 'recived_date', values=['qty']).reset_index()\n",
    "        df_out['sku_code'] = i\n",
    "        df0 = pd.concat([df0, df_out], axis = 0)\n",
    "    try:\n",
    "        df0.columns = df0.columns.get_level_values(level=1)\n",
    "    except:\n",
    "        pass\n",
    "    print(\"snap_df0_column before in snap\", df0.columns, \"len of df0 in snap\", (df0.shape))\n",
    "    df0 = df0.reset_index(drop = True) # 4 \n",
    "    # df0 = pd.DataFrame(np.zeros([3, 4]))\n",
    "    \"\"\"\n",
    "    添加缺失列\n",
    "    \"\"\"\n",
    "    if len(df0.columns) == 10:\n",
    "        print(list(df0.columns[0:scan_len]))\n",
    "        df0.columns = list(df0.columns[0:scan_len]) + ['received_date','sku']\n",
    "        print(\"normal process in snap::%s\"%str(df0.shape))\n",
    "    else:\n",
    "        # pass\n",
    "        print(\"auto fill enabled , ncol is: %s\" %(10 - len(df0.columns)))\n",
    "        # somelen = 10 - len(df0.columns)\n",
    "        # df_zero = pd.DataFrame(np.zeros([df0.shape[0], somelen]))\n",
    "        # df0 = pd.concat([df_zero, df0], axis = 1)\n",
    "        # df0.columns = list(\n",
    "        #     np.repeat(0, (somelen))\n",
    "        #     ) + list(\n",
    "        #         df0.columns[0:(scan_len)]\n",
    "        #         ) + ['received_date','sku']\n",
    "        names = df0.columns[0:2]\n",
    "        df_zero = pd.DataFrame(df0.iloc[:,0])\n",
    "        df_zero2 = pd.DataFrame()\n",
    "        # df_zero. copy()\n",
    "        for i in range(0,somelen):\n",
    "            df_zero2 = pd.concat([df_zero2, df_zero], axis = 1)\n",
    "\n",
    "        print(df_zero2.head())\n",
    "\n",
    "        df0 = pd.concat([df_zero2, df0], axis = 1)\n",
    "        print(df0.head())\n",
    "        df0.columns = list(range(11,11 + somelen)) + list(names) + ['received_date','sku']\n",
    "    scan_len = 8\n",
    "    print(df0.head())\n",
    "    df0 = df0.sort_values(['sku', 'received_date'])\n",
    "    df0['mark'] = 0\n",
    "    df0['mark'] = df0['mark'].where(\n",
    "        df0.iloc[:,  (scan_len - 1)].isna() == False, 'new')\n",
    "        # df0.iloc[:, 0: (scan_len - 1)].isna().all(axis = 1) == False, 'new')\n",
    "        # \n",
    "    df0['mark'] = df0['mark'].where(\n",
    "        ~df0.iloc[:,(scan_len - 1)].isna() , 'clear')\n",
    "    # fill na~\n",
    "    df0 = df0.fillna(0)\n",
    "    bose_inv = bose_inv.rename({'sku_code':'sku', 'recived_date':'received_date'}, axis = 1)\\\n",
    "        .reset_index(drop = True).drop(['inc_day', 'qty'], axis = 1)\n",
    "    bose_inv = bose_inv.drop_duplicates(subset = ['sku', 'received_date', 'lock_codes'])\n",
    "    df0 = df0.merge(bose_inv, on = ['sku','received_date'], how = 'left')\n",
    "\n",
    "    # may lock\n",
    "    df0['mark'] = df0['mark'].where(df0.iloc[:, 0:scan_len].fillna(0).nunique(axis = 1) > 1, 'may_lock')\n",
    "    print(\"===========================snap!done for : %s=============================\" %df0['ou_code'].unique())\n",
    "    return df0\n",
    "# print(\"===============================mid_function_check=================================\")\n",
    "def err_part():\n",
    "    \"\"\"\n",
    "    findout who are the naught peach.\n",
    "    err 中干掉了 new 干掉了maylock \n",
    "    \"\"\"\n",
    "    global df0\n",
    "\n",
    "    print(\"============================err_part!start: %s============================\"%str(df0.shape))\n",
    "    scan_len = 8\n",
    "    df_err = df0[df0['mark'] != 'new']\n",
    "    # 补充可能被锁的标记\n",
    "    # df_err['mark'] = df_err['mark'].where(df_err.iloc[:, 0:8].fillna(0).nunique(axis = 1) > 1, 'may_lock')\n",
    "    # 干掉了maylock\n",
    "    df_err = df_err[df_err['mark'] != 'may_lock'].sort_values(['sku', 'received_date'])\n",
    "    # print(\"===============================scan_len_err_function--%s=================================\"%scan_len)\n",
    "    # print(df_err.iloc[:,0:scan_len])\n",
    "    df_err['change'] = df_err.iloc[:,0:scan_len].diff(axis = 1).sum(axis = 1)\n",
    "    shift = df_err.groupby(['sku', 'wms_warehouse_id']).shift(1) \n",
    "    shift = shift[['mark','change']]\n",
    "    shift.columns = ['lag_mark', 'lag_change']\n",
    "    shift['lag_mark'] = shift['lag_mark'].where(~shift['lag_mark'].isna(), 'clear')\n",
    "    df_err = pd.concat([df_err, shift], axis = 1)\n",
    "    print(\"===============================err_part!done ::%s=================================\"%str(df_err.shape))\n",
    "    return df_err\n",
    "\n",
    "def output(df_err):\n",
    "    global df0\n",
    "    print(\"===============================output!start::%s=================================\"%str(df0.shape))\n",
    "\n",
    "    dishes = list(df_err[(df_err['lag_mark'] != 'clear') \\\n",
    "        & (df_err['change'] < 0)\n",
    "        & (df_err['change'] != df_err['lag_change'])]['sku'].unique())\n",
    "    print(\"===============================output!done::%s=================================\"%str((df0[df0['sku'].isin(dishes)]).shape))\n",
    "\n",
    "    return df0[df0['sku'].isin(dishes)]\n",
    "\n",
    "def check(sku):\n",
    "    global df0\n",
    "    a = df0[df0['sku'].isin(sku)].sort_values(['sku','received_date'])\n",
    "    print(\"===============================check!done::%s=================================\"%str(a.shape))\n",
    "\n",
    "    return a \n",
    "\n",
    "def ou_level_lock_codes(lock_code_to_eliminate):\n",
    "    \"\"\"\n",
    "    正则. lock_code 需要被排除的, 依赖view表格. \n",
    "    \"\"\" \n",
    "    print(\"===========================ou_level_lock_codes!start!code :: %s=============================\"%str(code))\n",
    "    select_none_lock  = pd.DataFrame(\n",
    "        view.groupby('sku')[\n",
    "            'mark'\n",
    "            ].apply(list).astype(str).str.match('.+may')\n",
    "        ).reset_index()\n",
    "\n",
    "    select_none_lock2 = pd.DataFrame(\n",
    "        view.groupby('sku')[\n",
    "            'lock_codes'\n",
    "            ].apply(list).astype(str).str.match('.+'+lock_code_to_eliminate)\n",
    "        ).reset_index()\n",
    "    # 去重    \n",
    "    bose_err_list = set(select_none_lock[~select_none_lock['mark']]['sku'].unique())\n",
    "    bose_err_list2 = list(select_none_lock2[~select_none_lock2['lock_codes']]['sku'].unique())\n",
    "    bose_err_list = list(bose_err_list.intersection(bose_err_list2))\n",
    "    bose_err_list = list(set(bose_err_list))\n",
    "    print(\"===========================ou_level_lock_codes!done :: %s===============================\"%str(bose_err_list))\n",
    "\n",
    "    return bose_err_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_part():\n",
    "    \"\"\"\n",
    "    findout who are the naught peach.\n",
    "    err 中干掉了 new 干掉了maylock \n",
    "    \"\"\"\n",
    "    df_err = df0[df0['mark'] != 'new']\n",
    "    # 补充可能被锁的标记\n",
    "    # df_err['mark'] = df_err['mark'].where(df_err.iloc[:, 0:8].fillna(0).nunique(axis = 1) > 1, 'may_lock')\n",
    "    # 干掉了maylock\n",
    "    df_err = df_err[df_err['mark'] != 'may_lock'].sort_values(['sku', 'received_date'])\n",
    "    df_err['change'] = df_err.iloc[:,0:8].diff(axis = 1).sum(axis = 1)\n",
    "    shift = df_err.groupby(['sku', 'wms_warehouse_id']).shift(1) \n",
    "    # q = []\n",
    "    # for i in shift['mark']:\n",
    "    #     if pd.isna(i):\n",
    "    #         q.append('clear')\n",
    "    #     elif i =='clear':\n",
    "    #         q.append('clear')\n",
    "    #     else:\n",
    "    #         q.append('check')\n",
    "    # shift['mark'] = q\n",
    "    # shift['mark2'] = shift.iloc[:,0:8].diff(axis = 1).sum(axis = 1)\n",
    "    shift = shift[['mark','change']]\n",
    "    shift.columns = ['lag_mark', 'lag_change']\n",
    "    shift['lag_mark'] = shift['lag_mark'].where(~shift['lag_mark'].isna(), 'clear')\n",
    "    df_err = pd.concat([df_err, shift], axis = 1)\n",
    "    # df_wrong = df_err[(df_err['lag_mark'] != 'clear') & (df_err['change'] != 0)]\n",
    "    # df_good  = df_err[(df_err['lag_mark'] != 'clear') | (df_err['change'] != 0)]\n",
    "    return df_err\n",
    "df_err = err_part()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_err.to_pickle('./data_up/df_err_bose.p')\n",
    "# df0.to_pickle('./data_up/df0_bose.p')\n",
    "# df_err_bose = pd.read_pickle('./data_up/df_err_bose.p')\n",
    "# df0_bose = pd.read_pickle('./data_up/df0_bose.p')\n",
    "# # df0_bose = df0_bose[df0_bose['wms_warehouse_id'] == 'BOSE_SH']\n",
    "# # df_err_bose = df_err_bose[df_err_bose['wms_warehouse_id'] == 'BOSE_SH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(\n",
    "#         view.groupby('sku')['mark'].apply(list).astype(str).str.contains('may') # may lock?\n",
    "#         ).reset_index()\n",
    "\n",
    "bose_inv['lock_codes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1000全新 3000退货 4000破损产品-\n",
    "\n",
    "bose_err_list = ou_level_lock_codes('(QH|QI|27)')\n",
    "bose_definite_wrong = check(bose_err_list, df0)\n",
    "bose_definite_wrong['lock_codes'].unique()\n",
    "    # .to_csv('./data_up/bose_fifo.csv', index = None, encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================\n",
    "# HP\n",
    "=================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# del df0 ,bose_inv\n",
    "bose_inv = load_data('HPI_WH');bose_inv\n",
    "df0 = pd.DataFrame()\n",
    "snapshot()\n",
    "\n",
    "# snapshot()\n",
    "df_err = err_part()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df0_hp['lock_codes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err.to_pickle('./data_up/df_err_hpwh.p')\n",
    "df0.to_pickle('./data_up/df0_hpwh.p')\n",
    "df_err_hp = pd.read_pickle('./data_up/df_err_hpwh.p')\n",
    "df0_hp = pd.read_pickle('./data_up/df0_hpwh.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = output(df_err_hp, df0_hp)\n",
    "err_list_hp = ou_level_lock_codes('(QH|27)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(sku, df0):\n",
    "    return df0[df0['sku'].isin(sku)]\n",
    "hp_definite_wrong = check(err_list_hp, df0_hp)\n",
    "\n",
    "# Z7Y79A 问一下\n",
    "# \n",
    "hp_definite_wrong.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp_definite_wrong[hp_definite_wrong['wms_warehouse_id']=='HPI_WH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_definite_wrong.to_csv('./data_up/hpwh_fifo.csv', index = None, encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp_definite_wrong[hp_definite_wrong['sku'] == '1VV21AA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_definite_wrong.to_csv('./data_up/hpsh_fifo.csv', index = None, encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================\n",
    "# michelin\n",
    "=================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = []\n",
    "bose_inv = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9[df9['wms_warehouse_name'] == 'OE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# del df0 ,bose_inv\n",
    "bose_inv = load_data('RT');bose_inv\n",
    "df0 = pd.DataFrame()\n",
    "snapshot()\n",
    "\n",
    "# snapshot()\n",
    "df_err = err_part()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err.to_pickle('./data_up/df_err_michrt.p')\n",
    "df0.to_pickle('./data_up/df0_michrt.p')\n",
    "df_err_mich = pd.read_pickle('./data_up/df_err_michrt.p')\n",
    "df0_mich = pd.read_pickle('./data_up/df0_michrt.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output(df0=df0_mich, df_err=df_err_mich).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df0_mich['lock_codes'].str.slice(0,7).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = output(df0=df0_mich, df_err=df_err_mich)\n",
    "err_list_mich = ou_level_lock_codes('(BLOCKED_TH|RETURN)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(sku, df0):\n",
    "    return df0[df0['sku'].isin(sku)]\n",
    "\n",
    "mich_definite_wrong = check(err_list_mich, df0 = df0_mich)\n",
    "\n",
    "# MATMICHELIN00591\n",
    "\n",
    "# 同一时间 received 货物为什么会增加\n",
    "# mich dot date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0_mich[df0_mich['sku'] == '085753_111']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mich_definite_wrong[mich_definite_wrong['sku'] == '085753_111']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mich_definite_wrong.to_csv('./data_up/michrt_fifo.csv', index = None, encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# del df0 ,bose_inv\n",
    "bose_inv = load_data('OE');bose_inv\n",
    "df0 = pd.DataFrame()\n",
    "snapshot()\n",
    "df_err = err_part()\n",
    "view = output(df0=df0, df_err=df_err)\n",
    "err_list_mich = ou_level_lock_codes('(BLOCKED_TH|RETURN)')\n",
    "def check(sku, df0):\n",
    "    return df0[df0['sku'].isin(sku)]\n",
    "\n",
    "mich_definite_wrong = check(err_list_mich, df0 = df0)\n",
    "\n",
    "mich_definite_wrong.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mich_definite_wrong.to_csv('./data_up/michoe_fifo.csv', index = None, encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================\n",
    "# fas <br>\n",
    "=========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bose_inv = load_data('FAS') \n",
    "df0 = pd.DataFrame()\n",
    "snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err = err_part()\n",
    "view = output(df_err, df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bose_inv.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_list_hp = ou_level_lock_codes('(Avi)') \n",
    "bose_inv[bose_inv['sku'] == err_list_hp[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check(sku, df0):\n",
    "    return df0[df0['sku'].isin(sku)]\n",
    "hp_definite_wrong = check(err_list_hp, df0)\n",
    "\n",
    "# hp_definite_wrong.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_definite_wrong.to_csv('./data_up/fas.csv', index = None, encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================\n",
    "# part2 <br>\n",
    "=========================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**select * from  dsc_dwd.dwd_wh_dsc_inventory_dtl_di \n",
    "where src = 'scale'\n",
    "and  ou_code in(\n",
    "'FERRECDXXS',\n",
    "'APPLESHWHW',\n",
    "'HUSQVSHMFS',\n",
    "'COSTASHHTS',\n",
    "'FUJIXSYXXS',\n",
    "'ZEBRASHALS'\n",
    ")\n",
    "and inc_day in ('20211124', '20211117', '20211110', '20211103', \n",
    "'20211027', '20211020', '20211013','20211006')\n",
    "and usage_flag = '1'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./data_down/inv_7_2.csv', sep='\\001')\n",
    "df.columns = [re.sub('\\w+\\.', '', i) for i in list(df.columns)]\n",
    "df = df.dropna(how = 'all', axis =1)\n",
    "time_cols = pd.Series(df.columns)[pd.Series(df.columns).str.lower().str.findall('date|time').apply(len)>0]\n",
    "df[time_cols] = df[time_cols].apply(lambda x: x.str.slice(0,10))\n",
    "df9 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ferrero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bose_inv = load_data('FERRECDXXS') \n",
    "df0 = pd.DataFrame()\n",
    "snapshot()\n",
    "df_err = err_part()\n",
    "view = output(df_err, df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_list_hp = ou_level_lock_codes('Blocked') \n",
    "bose_inv[bose_inv['sku'] == err_list_hp[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(sku, df0):\n",
    "    return df0[df0['sku'].isin(sku)]\n",
    "hp_definite_wrong = check(err_list_hp, df0)\n",
    "\n",
    "# hp_definite_wrong.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_definite_wrong.to_csv('./data_up/ferrero_FERRECDXXS.csv', index = None, encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apple sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ou_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bose_inv = load_data('APPLESHWHW') \n",
    "df0 = pd.DataFrame()\n",
    "snapshot()\n",
    "df_err = err_part()\n",
    "view = output(df_err, df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_list_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_list_hp = ou_level_lock_codes('ttt') \n",
    "# bose_inv[bose_inv['sku'] == err_list_hp[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(sku, df0):\n",
    "    return df0[df0['sku'].isin(sku)]\n",
    "hp_definite_wrong = check(err_list_hp, df0)\n",
    "\n",
    "# hp_definite_wrong.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp_definite_wrong[hp_definite_wrong['sku'] == '339S00668']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_definite_wrong.to_csv('./data_up/apple_sh_APPLESHWHW.csv', index = None, encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## costa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bose_inv = load_data('COSTASHHTS') \n",
    "df0 = pd.DataFrame()\n",
    "snapshot()\n",
    "df_err = err_part()\n",
    "view = output(df_err, df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_list_hp = ou_level_lock_codes('Held') \n",
    "df0[df0['sku'] == err_list_hp[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(sku, df0):\n",
    "    return df0[df0['sku'].isin(sku)]\n",
    "hp_definite_wrong = check(err_list_hp, df0)\n",
    "\n",
    "# hp_definite_wrong.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_definite_wrong.to_csv('./data_up/costa_COSTASHHTS.csv', index = None, encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZEBRASHALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bose_inv = load_data('ZEBRASHALS') \n",
    "df0 = pd.DataFrame()\n",
    "snapshot()\n",
    "df_err = err_part()\n",
    "view = output(df_err, df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_list_hp = ou_level_lock_codes('HOLD1') \n",
    "df0[df0['sku'] == err_list_hp[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(sku, df0):\n",
    "    return df0[df0['sku'].isin(sku)]\n",
    "hp_definite_wrong = check(err_list_hp, df0)\n",
    "\n",
    "hp_definite_wrong.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_definite_wrong.to_csv('./data_up/zebra_ZEBRASHALS.csv', index = None, encoding = 'utf_8_sig')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47b50d2908d96196e4220cfb4e81faa93803065ea975497e7026f672c1f58470"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('siming': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
